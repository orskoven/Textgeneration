{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Interactive Random Forest Classifier on MNIST Dataset\n",
       "\n",
       "This notebook demonstrates the use of a Random Forest Classifier on the MNIST dataset. Interactive tuning of hyperparameters will help understand how entropy and Gini impurity impact the model performance, focusing on principles of supervised learning, feature extraction, and classification boundaries."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Import necessary libraries\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "from sklearn.datasets import fetch_openml\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.ensemble import RandomForestClassifier\n",
       "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "import seaborn as sns\n",
       "from ipywidgets import interact, IntSlider, Dropdown, ToggleButtons\n",
       "import warnings\n",
       "warnings.filterwarnings('ignore')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Load and Preprocess the MNIST Dataset"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Load MNIST dataset\n",
       "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
       "X, y = mnist.data, mnist.target.astype(np.int8)\n",
       "\n",
       "# Normalize the data\n",
       "scaler = StandardScaler()\n",
       "X_scaled = scaler.fit_transform(X)\n",
       "\n",
       "# Split into training and test sets\n",
       "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
       "\n",
       "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
       "print(f\"Test set size: {X_test.shape[0]} samples\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Define Function to Train, Evaluate the Model, and Visualize Results"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def train_evaluate_rf(n_estimators, max_depth, max_features, criterion):\n",
       "    \"\"\"\n",
       "    Train and evaluate a Random Forest classifier with given hyperparameters.\n",
       "    Parameters:\n",
       "    - n_estimators: Number of trees in the forest\n",
       "    - max_depth: Maximum depth of each tree\n",
       "    - max_features: Maximum number of features considered for splitting\n",
       "    - criterion: Splitting criterion ('gini' or 'entropy')\n",
       "    \"\"\"\n",
       "    rf = RandomForestClassifier(\n",
       "        n_estimators=n_estimators,\n",
       "        max_depth=max_depth if max_depth > 0 else None,\n",
       "        max_features=max_features,\n",
       "        criterion=criterion,\n",
       "        random_state=42,\n",
       "        n_jobs=-1\n",
       "    )\n",
       "    \n",
       "    rf.fit(X_train, y_train)\n",
       "    y_pred = rf.predict(X_test)\n",
       "    accuracy = accuracy_score(y_test, y_pred)\n",
       "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
       "    \n",
       "    cm = confusion_matrix(y_test, y_pred)\n",
       "    plt.figure(figsize=(10, 7))\n",
       "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
       "    plt.xlabel('Predicted')\n",
       "    plt.ylabel('Actual')\n",
       "    plt.title('Confusion Matrix')\n",
       "    plt.show()\n",
       "    \n",
       "    print(\"Classification Report:\")\n",
       "    print(classification_report(y_test, y_pred))\n",
       "\n",
       "    # Feature importance visualization\n",
       "    feature_importances = rf.feature_importances_\n",
       "    sorted_idx = np.argsort(feature_importances)[-10:]\n",
       "    plt.figure(figsize=(8, 6))\n",
       "    sns.barplot(x=feature_importances[sorted_idx], y=sorted_idx, orient='h', palette='viridis')\n",
       "    plt.xlabel('Feature Importance')\n",
       "    plt.ylabel('Feature Index')\n",
       "    plt.title('Top 10 Feature Importances')\n",
       "    plt.show()\n",
       "    \n",
       "    # Accuracy over a range of trees for visualization\n",
       "    accuracy_list = []\n",
       "    n_estimator_range = range(10, n_estimators+1, 10)\n",
       "    for n in n_estimator_range:\n",
       "        temp_rf = RandomForestClassifier(n_estimators=n, criterion=criterion, random_state=42, n_jobs=-1)\n",
       "        temp_rf.fit(X_train, y_train)\n",
       "        accuracy_list.append(accuracy_score(y_test, temp_rf.predict(X_test)))\n",
       "    plt.figure(figsize=(10, 6))\n",
       "    sns.lineplot(x=list(n_estimator_range), y=accuracy_list)\n",
       "    plt.xlabel('Number of Trees')\n",
       "    plt.ylabel('Accuracy')\n",
       "    plt.title('Accuracy vs. Number of Trees in Random Forest')\n",
       "    plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Interactive Widget for Hyperparameter Tuning\n",
       "\n",
       "Select the parameters below to see how different settings affect model performance. Consider how the choice of splitting criterion (Gini impurity vs. entropy) influences decision-making, and observe the changes in accuracy, confusion matrix, feature importances, and the effect of different numbers of trees."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "n_estimators_slider = IntSlider(\n",
       "    value=100,\n",
       "    min=10,\n",
       "    max=500,\n",
       "    step=10,\n",
       "    description='n_estimators'\n",
       ")\n",
       "\n",
       "max_depth_slider = IntSlider(\n",
       "    value=10,\n",
       "    min=0,\n",
       "    max=50,\n",
       "    step=1,\n",
       "    description='max_depth'\n",
       ")\n",
       "\n",
       "max_features_dropdown = Dropdown(\n",
       "    options=['auto', 'sqrt', 'log2'],\n",
       "    value='auto',\n",
       "    description='max_features'\n",
       ")\n",
       "\n",
       "criterion_toggle = ToggleButtons(\n",
       "    options=['gini', 'entropy'],\n",
       "    description='criterion',\n",
       "    button_style='info'\n",
       ")\n",
       "\n",
       "interact(\n",
       "    train_evaluate_rf,\n",
       "    n_estimators=n_estimators_slider,\n",
       "    max_depth=max_depth_slider,\n",
       "    max_features=max_features_dropdown,\n",
       "    criterion=criterion_toggle\n",
       ");"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }
   